{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing cloud satellite data\n",
    "\n",
    "- Funding: Interagency Implementation and Advanced Concepts Team [IMPACT](https://earthdata.nasa.gov/esds/impact) for the Earth Science Data Systems (ESDS) program and AWS Public Dataset Program\n",
    "  \n",
    "### Credits: Tutorial development\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org) -  [Twitter](https://twitter.com/ChelleGentemann)   - Farallon Institute\n",
    "* [Patrick Gray](mailto:patrick.c.gray@duke.edu) - [Twitter](https://twitter.com/clifgray) Duke University\n",
    "* [Kylene Cooley](mailto:cooleyky@oregonstate.edu) - Oregon State University\n",
    "* [Phoebe Hudson](mailto:pahdsn@outlook.com) - [Twitter](https://twitter.com/pahdsn) - National Oceanography Centre\n",
    "\n",
    "### Data proximate computing\n",
    "These are BIG datasets that you can analyze on the cloud without downloading the data.  \n",
    "You can run this on your phone, a Raspberry Pi, laptop, or desktop.   \n",
    "By using public cloud data, your science is reproducible and easily shared!\n",
    "\n",
    "### Here we will demonstrate some ways to access two different geostationary SST datasets on AWS:\n",
    "- AWS GOES sea surface temperatures  (L2)\n",
    "- AWS Himawari sea surface temperatures (L2 and L3)\n",
    "\n",
    "### To run this notebook\n",
    "\n",
    "Code is in the cells that have <span style=\"color: blue;\">In [  ]:</span> to the left of the cell and have a colored background\n",
    "\n",
    "To run the code:\n",
    "- option 1) click anywhere in the cell, then hold `shift` down and press `Enter`\n",
    "- option 2) click on the Run button at the top of the page in the dashboard\n",
    "\n",
    "Remember:\n",
    "- to insert a new cell below press `Esc` then `b`\n",
    "- to delete a cell press `Esc` then `dd`\n",
    "\n",
    "### First start by importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter some warning messages\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "#libraries\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import s3fs\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# make datasets display nicely\n",
    "xr.set_options(display_style=\"html\")  \n",
    "\n",
    "#magic fncts #put static images of your plot embedded in the notebook\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import metpy  # noqa: F401"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "# How to find an AWS Public Dataset\n",
    "\n",
    "- click here: [AWS Public Dataset](https://aws.amazon.com/opendata/)\n",
    "- Click on `Find public available data on AWS` button\n",
    "- Search for GOES\n",
    "- Select [GOES-16 and GOES-17](https://registry.opendata.aws/noaa-goes/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetCDF geostationary data\n",
    "\n",
    "- Info on the data is here -- GOES has a lot of different parameters and they are all stored in different files with names that are difficult to understand.  There are *80* different data products.  This link lists them all and explains the different directory names. [AWS info on GOES SST data](https://docs.opendata.aws/noaa-goes16/cics-readme.html).  \n",
    "\n",
    "- The GOES data is netCDF format.  There is a different file for each of the 80 projects for year/day/hour.  A lot of files.  I find it really useful to 'browse' s3: buckets so that I can understand the directory and data structure.  [Explore S3 structure](https://noaa-goes16.s3.amazonaws.com/index.html).  The directory structure is `<Product>/<Year>/<Day of Year>/<Hour>/<Filename>`\n",
    "\n",
    "- In the code below we are going to create a function that searches for all files from a certain day, then creates the keys to opening them.  The files are so messy that opening a day takes a little while.  There are other ways you could write this function depending on what your analysis goals are, this is just one way to get some data in a reasonable amount of time. \n",
    "- This function uses \n",
    "- [`s3fs.S3FileSystem`](https://s3fs.readthedocs.io/en/latest/) which holds a connection with a s3 bucket and allows you to list files, etc.  \n",
    "- [`xr.open_mfdataset`](http://xarray.pydata.org/en/stable/generated/xarray.open_mfdataset.html#xarray.open_mfdataset) opens a list of filenames and concatenates the data along the specified dimensions  \n",
    "\n",
    "Website [https://registry.opendata.aws/noaa-goes/](https://registry.opendata.aws/noaa-goes/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_data(sat,lyr,idyjl):\n",
    "    # arguments\n",
    "    # sat   goes-east,goes-west,himawari\n",
    "    # lyr   year\n",
    "    # idyjl day of year\n",
    "    \n",
    "    d = dt.datetime(lyr,1,1) + dt.timedelta(days=idyjl)\n",
    "    fs = s3fs.S3FileSystem(anon=True) #connect to s3 bucket!\n",
    "\n",
    "    #create strings for the year and julian day\n",
    "    imon,idym=d.month,d.day\n",
    "    syr,sjdy,smon,sdym = str(lyr).zfill(4),str(idyjl).zfill(3),str(imon).zfill(2),str(idym).zfill(2)\n",
    "    \n",
    "    #use glob to list all the files in the directory\n",
    "    if sat=='goes-east':\n",
    "        file_location,var = fs.glob('s3://noaa-goes16/ABI-L2-SSTF/'+syr+'/'+sjdy+'/*/*.nc'),'SST'\n",
    "    if sat=='goes-west':\n",
    "        file_location,var = fs.glob('s3://noaa-goes17/ABI-L2-SSTF/'+syr+'/'+sjdy+'/*/*.nc'),'SST'\n",
    "    if sat=='himawari':\n",
    "        file_location,var = fs.glob('s3://noaa-himawari8/AHI-L2-FLDK-SST/'+syr+'/'+smon+'/'+sdym+'/*/*L2P*.nc'),'sea_surface_temperature'\n",
    "    \n",
    "    #make a list of links to the file keys\n",
    "    if len(file_location)<1:\n",
    "        return file_ob\n",
    "    file_ob = [fs.open(file) for file in file_location]        #open connection to files\n",
    "    \n",
    "    #open all the day's data\n",
    "    ds = xr.open_mfdataset(file_ob,combine='nested',concat_dim='time') #note file is super messed up formatting\n",
    "    \n",
    "    #clean up coordinates which are a MESS in GOES\n",
    "    #rename one of the coordinates that doesn't match a dim & should\n",
    "    if not sat=='himawari':\n",
    "        ds = ds.rename({'t':'time'})\n",
    "        ds = ds.reset_coords()\n",
    "    else:\n",
    "        ds = ds.rename({'ni':'x','nj':'y'})\n",
    "    \n",
    "    #put in to Celsius\n",
    "    #ds[var] -= 273.15   #nice python shortcut to +- from itself a-=273.15 is the same as a=a-273.15\n",
    "    #ds[var].attrs['units'] = '$^\\circ$C'\n",
    "   \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a day of GOES-16  (East Coast) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lyr, idyjl = 2020, 210  #may 30, 2020\n",
    "\n",
    "ds = get_geo_data('goes-east',lyr,idyjl)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "subset = ds.sel(x=slice(-0.01,0.07215601),y=slice(0.12,0.09))  #reduce to GS region\n",
    "\n",
    "masked = subset.SST.where(subset.DQF==0)\n",
    "\n",
    "masked.isel(time=14).plot(vmin=15+273.15,vmax=30+273.15,cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#mean_dy = masked.mean('time',skipna=True)   #here I want all possible values so skipna=True\n",
    "\n",
    "#mean_dy.plot(vmin=14+273.15,vmax=30+273.15,cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Disc Image\n",
    "This geostationary satellite records an hourly time series of a single disk-shaped view of the Earth. The next cells plot the mean of a 36-hour time slice for the entire spatial domain and a section of the Gulf Stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_e = ds.where(ds.DQF==0) # selects only 'good quality' SST data\n",
    "masked_e = masked_e.isel(time=slice(0,36)) # slice of first 36 hours of time series including endpoints\n",
    "masked_e = masked_e.SST.mean('time',skipna=True) # taking the mean in the time domain\n",
    "\n",
    "gs_subset = ds.sel(x=slice(-0.012,0.012),y=slice(0.12,0.085))  # reduce to Gulf Stream region\n",
    "masked_subset = gs_subset.SST.where(gs_subset.DQF==0) # 'good' data\n",
    "masked_subset = masked_subset.isel(time=slice(0,36)) # time slice\n",
    "masked_subset = masked_subset.mean('time')  # temporal mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with Matplotlib.pyplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,6))\n",
    "\n",
    "masked_e.plot(ax=ax[0], cmap='inferno', add_colorbar=False)\n",
    "ax[0].axis('off')\n",
    "\n",
    "masked_subset.plot(ax=ax[1], cmap='inferno', add_colorbar=False)\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[0].set_title('GOES-East')\n",
    "ax[1].set_title('Gulf Stream')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make geo-referenced map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = ds.metpy.parse_cf('SST')\n",
    "x = dat.x\n",
    "y = dat.y\n",
    "\n",
    "H = ds.goes_imager_projection.attrs['perspective_point_height'][0]\n",
    "\n",
    "lon_0 = ds.nominal_satellite_subpoint_lon[0].data\n",
    "\n",
    "img_proj = ccrs.Geostationary(satellite_height=H,central_longitude=lon_0,sweep_axis='x')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=img_proj)\n",
    "\n",
    "masked = ds.SST.where(ds.DQF==0)\n",
    "\n",
    "ax.imshow(masked.isel(time=14), origin='upper',\n",
    "          extent=(x.min(), x.max(), y.min(), y.max()),\n",
    "          transform=img_proj)\n",
    "\n",
    "ax.coastlines(color='black') #, resolution='10m')\n",
    "ax.add_feature(cfeature.LAKES.with_scale('10m'), facecolor='none', edgecolor='tab:blue')\n",
    "#ax.add_feature(cfeature.RIVERS.with_scale('10m'), edgecolor='tab:blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read AWS JMA Himawari SSTs\n",
    "- define a function to get all the filenames for a day\n",
    "- AWS info on Himawari SST data, [here](https://www.goes.noaa.gov/f_himawari-8.html)\n",
    "- Explore S3 structure [here](https://noaa-himawari8.s3.amazonaws.com/index.html)\n",
    "- SSTs are given in L2P and L3C GHRSST data formats.\n",
    "L2P has dims that not mapped to a regular grid.  \n",
    "L3C is mapped to a grid, with dims lat,lon.\n",
    "Here we use L2P.\n",
    "\n",
    "Website [https://registry.opendata.aws/noaa-himawari/](https://registry.opendata.aws/noaa-himawari/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lyr, idyjl = 2020, 220\n",
    "\n",
    "ds = get_geo_data('himawari',lyr,idyjl)\n",
    "\n",
    "subset = ds.sel(x=slice(-0.05,0.08),y=slice(0.12,0.08))\n",
    "\n",
    "masked = subset.sea_surface_temperature.where(subset.quality_level>=4)\n",
    "\n",
    "masked[0,:,:].plot(vmin=14+273.15,vmax=28+273.15,cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = ds.metpy.parse_cf('sea_surface_temperature')\n",
    "x = dat.x\n",
    "y = dat.y\n",
    "\n",
    "H = ds.attrs['Dist_Virt_Sat'][0]\n",
    "\n",
    "lon_0 = ds.attrs['Sub_Lon'][0]\n",
    "\n",
    "img_proj = ccrs.Geostationary(satellite_height=H,central_longitude=lon_0,sweep_axis='x')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=img_proj)\n",
    "\n",
    "masked = ds.sea_surface_temperature.where(ds.quality_level>=4)\n",
    "\n",
    "ax.imshow(masked.isel(time=14), origin='upper',\n",
    "          extent=(x.min(), x.max(), y.min(), y.max()),\n",
    "          transform=img_proj)\n",
    "\n",
    "ax.coastlines(color='black') #, resolution='10m')\n",
    "ax.add_feature(cfeature.LAKES.with_scale('10m'), facecolor='none', edgecolor='tab:blue')\n",
    "#ax.add_feature(cfeature.RIVERS.with_scale('10m'), edgecolor='tab:blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
